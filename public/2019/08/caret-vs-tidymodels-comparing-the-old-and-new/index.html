

  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.56.3">
    <title>Caret vs. tidymodels - comparing the old and new</title>
    <meta name="author" content="Konrad Semsch">
    <meta name="keywords" content=", data science, statistics, machine learning, predictive modelling, fintech, banking, r">

    <link rel="icon" href="/favicon.png">
    

    
    <meta name="description" content="




In this post I will make a comparison between the most popular (by number of monthly downloads from Github) ML framework available for R to date: caret and its successor packages being written by the same author (Max Kuhn) that are wrapped together in a so called tidymodels framework.
">
    <meta property="og:description" content="




In this post I will make a comparison between the most popular (by number of monthly downloads from Github) ML framework available for R to date: caret and its successor packages being written by the same author (Max Kuhn) that are wrapped together in a so called tidymodels framework.
">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Caret vs. tidymodels - comparing the old and new">
    <meta property="og:url" content="/2019/08/caret-vs-tidymodels-comparing-the-old-and-new/">
    <meta property="og:site_name" content="Practitioners view on predictive modelling">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Practitioners view on predictive modelling">
    <meta name="twitter:description" content="




In this post I will make a comparison between the most popular (by number of monthly downloads from Github) ML framework available for R to date: caret and its successor packages being written by the same author (Max Kuhn) that are wrapped together in a so called tidymodels framework.
">
    
    

    
    

    
      <meta property="og:image" content="/images/profile.png">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">Practitioners view on predictive modelling</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="/images/profile.png" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="/images/profile.png" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Konrad Semsch</h4>
        
          <h5 class="sidebar-profile-bio">Practitioners view on predictive modelling</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <b><i class="sidebar-button-icon fa fa-lg fa-home"></i></b>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.linkedin.com/in/konradsemsch/">
    
      <i class="sidebar-button-icon fa fa-linkedin-square"></i>
      
      <span class="sidebar-button-desc">Linkedin</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/konradsemsch">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Caret vs. tidymodels - comparing the old and new
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-08-06T00:00:00Z">
        
  
  
  
  
    6 August 2019
  

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/predictive-modelling">predictive modelling</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <p>In this post I will make a comparison between the most popular (by number of monthly downloads from Github) ML framework available for R to date: <a href="https://github.com/topepo/caret">caret</a> and its successor packages being written by the same author (<a href="https://github.com/topepo">Max Kuhn</a>) that are wrapped together in a so called <a href="https://github.com/tidymodels/tidymodels">tidymodels</a> framework. <code>Tidymodels</code> is a collection of different packages such as: <a href="https://tidymodels.github.io/rsample/">rsample</a>, <a href="https://tidymodels.github.io/recipes/">recipes</a>, <a href="https://tidymodels.github.io/parsnip/">parsnip</a>, <a href="https://tidymodels.github.io/dials/">dials</a> and more, that allow running an entire ML project in a tidy format end-to-end.</p>
<p>Many of them are still in a development phase, which will still take a couple good months before they settle down, so I’ll try to keep this post up-to-date over time. Nevertheless, I’ve wanted to take a closer look at what <code>tidymodels</code> have to offer for a while already, and thought a blogpost would be a great way to demonstrate that.</p>
<p>In order to write this blog I’ve been reading carefully all individual package websites and this excellent <a href="https://www.alexpghayes.com/blog/implementing-the-super-learner-with-tidymodels/">blogpost</a> from Alex Hayes helped me a lot to put things together.</p>
<div id="initial-setup" class="section level1">
<h1>Initial setup</h1>
<p>In the beginning, let’s load all the required packages and the <code>credit_data</code> dataset available from <code>recipes</code> that we will use for modelling. Note also that I’m setting the random seed to make sampling reproducible, as well as set the <a href="https://davisvaughan.github.io/furrr/">furrr</a> plan to <code>multicore</code>. It’s important unless you want this script to run really long on your machine - we’ll be fitting many different models, so making sure you utilize all your local resources will speed things up a lot.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">42</span>)
<span class="kw">options</span>(<span class="dt">max.print =</span> <span class="dv">150</span>)

<span class="kw">library</span>(tidymodels)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(caret)
<span class="kw">library</span>(magrittr)
<span class="kw">library</span>(naniar)
<span class="kw">library</span>(furrr)
<span class="kw">library</span>(skimr)

<span class="kw">plan</span>(multicore)  
<span class="kw">data</span>(<span class="st">&quot;credit_data&quot;</span>)</code></pre>
</div>
<div id="data-preparation" class="section level1">
<h1>Data preparation</h1>
<p>In this example, I’m building a classification model to distinguish between good and bad loans indicated by column ‘Status’. We have relatively many observations compared to the number of variables available for modelling. Before making any other steps let’s convert all columns to lowercase.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(credit_data)</code></pre>
<pre><code>## Observations: 4,454
## Variables: 14
## $ Status    &lt;fct&gt; good, good, bad, good, good, good, good, good, good, b…
## $ Seniority &lt;int&gt; 9, 17, 10, 0, 0, 1, 29, 9, 0, 0, 6, 7, 8, 19, 0, 0, 15…
## $ Home      &lt;fct&gt; rent, rent, owner, rent, rent, owner, owner, parents, …
## $ Time      &lt;int&gt; 60, 60, 36, 60, 36, 60, 60, 12, 60, 48, 48, 36, 60, 36…
## $ Age       &lt;int&gt; 30, 58, 46, 24, 26, 36, 44, 27, 32, 41, 34, 29, 30, 37…
## $ Marital   &lt;fct&gt; married, widow, married, single, single, married, marr…
## $ Records   &lt;fct&gt; no, no, yes, no, no, no, no, no, no, no, no, no, no, n…
## $ Job       &lt;fct&gt; freelance, fixed, freelance, fixed, fixed, fixed, fixe…
## $ Expenses  &lt;int&gt; 73, 48, 90, 63, 46, 75, 75, 35, 90, 90, 60, 60, 75, 75…
## $ Income    &lt;int&gt; 129, 131, 200, 182, 107, 214, 125, 80, 107, 80, 125, 1…
## $ Assets    &lt;int&gt; 0, 0, 3000, 2500, 0, 3500, 10000, 0, 15000, 0, 4000, 3…
## $ Debt      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2500, 260, 0, 0, 0…
## $ Amount    &lt;int&gt; 800, 1000, 2000, 900, 310, 650, 1600, 200, 1200, 1200,…
## $ Price     &lt;int&gt; 846, 1658, 2985, 1325, 910, 1645, 1800, 1093, 1957, 14…</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">credit_data <span class="op">%&lt;&gt;%</span>
<span class="st">  </span><span class="kw">set_names</span>(., <span class="kw">tolower</span>(<span class="kw">names</span>(.)))</code></pre>
<p>With the help of the excellent <a href="http://naniar.njtierney.com/">naniar</a> package I’m checking the percentage of missing data per each variable. For this particular dataset there are very few missing values so they won’t pose a problem for us during modelling.</p>
<pre class="sourceCode r"><code class="sourceCode r">credit_data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">miss_var_summary</span>()</code></pre>
<pre><code>## # A tibble: 14 x 3
##    variable  n_miss pct_miss
##    &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;
##  1 income       381   8.55  
##  2 assets        47   1.06  
##  3 debt          18   0.404 
##  4 home           6   0.135 
##  5 job            2   0.0449
##  6 marital        1   0.0225
##  7 status         0   0     
##  8 seniority      0   0     
##  9 time           0   0     
## 10 age            0   0     
## 11 records        0   0     
## 12 expenses       0   0     
## 13 amount         0   0     
## 14 price          0   0</code></pre>
<p>Another important step would be to make some basic numerical summaries of the data in order to catch any unusual observations. I will do it using the <a href="https://ropensci.github.io/skimr/">skimr</a> package. Apart from the fact that many numerical variables show high skewness and some categorical variables have levels with very low frequency, it doesn’t seem that we will have to deal with any special encoded numbers or other problems.</p>
<pre class="sourceCode r"><code class="sourceCode r">credit_data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">skim</span>()</code></pre>
<pre><code>## Skim summary statistics
##  n obs: 4454 
##  n variables: 14 
## 
## ── Variable type:factor ────────────────────────────────────────────────────────
##  variable missing complete    n n_unique
##      home       6     4448 4454        6
##       job       2     4452 4454        4
##   marital       1     4453 4454        5
##   records       0     4454 4454        2
##    status       0     4454 4454        2
##                                top_counts ordered
##   own: 2107, ren: 973, par: 783, oth: 319   FALSE
##  fix: 2805, fre: 1024, par: 452, oth: 171   FALSE
##    mar: 3241, sin: 977, sep: 130, wid: 67   FALSE
##                 no: 3681, yes: 773, NA: 0   FALSE
##               goo: 3200, bad: 1254, NA: 0   FALSE
## 
## ── Variable type:integer ───────────────────────────────────────────────────────
##   variable missing complete    n    mean       sd  p0     p25  p50    p75
##        age       0     4454 4454   37.08    10.98  18   28      36   45  
##     amount       0     4454 4454 1038.92   474.55 100  700    1000 1300  
##     assets      47     4407 4454 5403.98 11574.42   0    0    3000 6000  
##       debt      18     4436 4454  343.03  1245.99   0    0       0    0  
##   expenses       0     4454 4454   55.57    19.52  35   35      51   72  
##     income     381     4073 4454  141.69    80.75   6   90     125  170  
##      price       0     4454 4454 1462.78   628.13 105 1117.25 1400 1691.5
##  seniority       0     4454 4454    7.99     8.17   0    2       5   12  
##       time       0     4454 4454   46.44    14.66   6   36      48   60  
##   p100     hist
##     68 ▅▇▇▇▅▃▂▁
##   5000 ▅▇▃▁▁▁▁▁
##  3e+05 ▇▁▁▁▁▁▁▁
##  30000 ▇▁▁▁▁▁▁▁
##    180 ▇▃▃▁▁▁▁▁
##    959 ▇▆▁▁▁▁▁▁
##  11140 ▇▆▁▁▁▁▁▁
##     48 ▇▃▂▁▁▁▁▁
##     72 ▁▁▂▃▁▃▇▁</code></pre>
<p>Another point we need to keep in mind when dealing with credit scoring problems is something called a target <a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/">class imbalance</a>, but in this particular case it’s not that severe. For the sake of comparing programming frameworks and not implementing the best ML model I will ignore it.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(credit_data<span class="op">$</span>status)</code></pre>
<pre><code>## 
##  bad good 
## 1254 3200</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">prop.table</span>(<span class="kw">table</span>(credit_data<span class="op">$</span>status)), <span class="dv">2</span>)</code></pre>
<pre><code>## 
##  bad good 
## 0.28 0.72</code></pre>
</div>
<div id="data-preparation-1" class="section level1">
<h1>Data preparation</h1>
<p>Let’s finally move on and start modelling! In the beginning I’ll start with dividing our dataset into training and testing sets with the help of the <code>rsample</code> package. Let’s set an initial, stratified split where 80% of the data is dedicated to training and the rest to evaluating both models.</p>
<p>Furthermore, I’m creating cross-validation splits from the testing data of 5 folds. For compatibility with <code>caret</code> I’m using the <code>rsample2caret</code> function to make use of the same splits in both frameworks - otherwise both solutions wouldn’t be 100% comparable.</p>
<pre class="sourceCode r"><code class="sourceCode r">split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(credit_data, <span class="dt">prop =</span> <span class="fl">0.80</span>, <span class="dt">strata =</span> <span class="st">&quot;status&quot;</span>)

df_train &lt;-<span class="st"> </span><span class="kw">training</span>(split)
df_test  &lt;-<span class="st"> </span><span class="kw">testing</span>(split)

train_cv &lt;-<span class="st"> </span><span class="kw">vfold_cv</span>(df_train, <span class="dt">v =</span> <span class="dv">5</span>, <span class="dt">strata =</span> <span class="st">&quot;status&quot;</span>)
train_cv_caret &lt;-<span class="st"> </span><span class="kw">rsample2caret</span>(train_cv)

<span class="co"># write_rds(split, &quot;split.rds&quot;)</span>
<span class="co"># write_rds(train_cv, &quot;train_cv.rds&quot;)</span></code></pre>
<p>I would like to fit a Random Forest model for which I will specify a simple <code>recipe</code>. In principle, tree-based models require very little preprocessing, and in this particular example I mainly focus on imputting missing data or assigning them a new categorical level, infrequent/ unobserved values and hot-encoding them. The same recipe will be used for both: <code>caret</code> and <code>tidymodels</code> model.</p>
<p>Normally I would do much more feature engineering, try to assess potential interactions etc., but I will write a separate post dedicated for that to so see how much further we can improve the model!</p>
<pre class="sourceCode r"><code class="sourceCode r">recipe &lt;-<span class="st"> </span>df_train <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">recipe</span>(status <span class="op">~</span><span class="st"> </span>.) <span class="op">%&gt;%</span>

<span class="st">  </span><span class="co"># Imputation: assigning NAs to a new level for categorical and median imputation for numeric</span>
<span class="st">  </span><span class="kw">step_unknown</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span>status) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">step_medianimpute</span>(<span class="kw">all_numeric</span>()) <span class="op">%&gt;%</span>

<span class="st">  </span><span class="co"># Combining infrequent categorical levels and introducing a new level for prediction time</span>
<span class="st">  </span><span class="kw">step_other</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span>status, <span class="dt">other =</span> <span class="st">&quot;infrequent_combined&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_novel</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span>status, <span class="dt">new_level =</span> <span class="st">&quot;unrecorded_observation&quot;</span>) <span class="op">%&gt;%</span>

<span class="st">  </span><span class="co"># Hot-encoding categorical variables</span>
<span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span>status, <span class="dt">one_hot =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>

<span class="st">  </span><span class="co"># Taking care of output consistency</span>
<span class="st">  </span><span class="kw">check_missing</span>(<span class="kw">all_predictors</span>())</code></pre>
<p>Let’s take a quick look at the output of the recipe:</p>
<pre class="sourceCode r"><code class="sourceCode r">(recipe_preped &lt;-<span class="st"> </span><span class="kw">prep</span>(recipe, <span class="dt">retain =</span> <span class="ot">TRUE</span>))</code></pre>
<pre><code>## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         13
## 
## Training data contained 3565 data points and 333 incomplete rows. 
## 
## Operations:
## 
## Unknown factor level assignment for home, marital, records, job [trained]
## Median Imputation for seniority, time, age, expenses, ... [trained]
## Collapsing factor levels for home, marital, records, job [trained]
## Novel factor level assignment for home, marital, records, job [trained]
## Dummy variables from home, marital, records, job [trained]
## Check missing values for seniority, time, age, expenses, ... [trained]</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(recipe_preped)</code></pre>
<pre><code>## # A tibble: 6 x 6
##   number operation type         trained skip  id                
##    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;             
## 1      1 step      unknown      TRUE    FALSE unknown_5CFHt     
## 2      2 step      medianimpute TRUE    FALSE medianimpute_Hkncr
## 3      3 step      other        TRUE    FALSE other_tZVMD       
## 4      4 step      novel        TRUE    FALSE novel_KC08V       
## 5      5 step      dummy        TRUE    FALSE dummy_05QZl       
## 6      6 check     missing      TRUE    FALSE missing_pfTs9</code></pre>
</div>
<div id="fitting-our-models" class="section level1">
<h1>Fitting our models</h1>
<div id="caret" class="section level2">
<h2>Caret</h2>
<p>In the code below I’m setting control parameters for the <code>caret</code> model fit, as well as the grid of hyperparameters that will be assessed in order to pick the best performing combination. Note that I’m using the very original observation indexes for cross-validation to ensure reproducability. The <code>trainControl</code> function will also ensure that final hold-out predictions from cross-validation will be persisted for further assessment thanks to <code>savePredictions = &quot;final&quot;</code>.</p>
<p>We have 5 different CV folds and 30 grid combinations to assess, which results in 150 models that will be fit and each comprising of 500 individual trees! All models will be assessed based on the <code>prSummary</code> function which is know as the AUC.</p>
<pre><code>##    mtry  splitrule min.node.size
## 1     1 extratrees             1
## 2     4 extratrees             1
## 3     7 extratrees             1
## 4    10 extratrees             1
## 5    13 extratrees             1
## 6     1       gini             1
## 7     4       gini             1
## 8     7       gini             1
## 9    10       gini             1
## 10   13       gini             1
## 11    1 extratrees             3
## 12    4 extratrees             3
## 13    7 extratrees             3
## 14   10 extratrees             3
## 15   13 extratrees             3
## 16    1       gini             3
## 17    4       gini             3
## 18    7       gini             3
## 19   10       gini             3
## 20   13       gini             3
## 21    1 extratrees             5
## 22    4 extratrees             5
## 23    7 extratrees             5
## 24   10 extratrees             5
## 25   13 extratrees             5
## 26    1       gini             5
## 27    4       gini             5
## 28    7       gini             5
## 29   10       gini             5
## 30   13       gini             5</code></pre>
<p>The great advantage of <code>caret</code> is that it wraps a lot of small code pieces in just one, high-level API call that does all the job for you - fits all individual models across CV folds and resamples, selects the best one and fits it already on the entire training dataset. It also makes sure it’s done as fast as possible thanks to parallel processing whenever it’s an enabled option.</p>
<p>The drawback on the other hand is that it’s quite monolythic, untidy and at the end doesn’t offer a great deal of granularity to the end user.</p>
<pre class="sourceCode r"><code class="sourceCode r">model_caret &lt;-<span class="st"> </span><span class="kw">train</span>(
  status <span class="op">~</span><span class="st"> </span>.,
  <span class="dt">data =</span> <span class="kw">juice</span>(recipe_preped),
  <span class="dt">method =</span> <span class="st">&quot;ranger&quot;</span>,
  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,
  <span class="dt">trControl =</span> control_caret,
  <span class="dt">tuneGrid =</span> grid_caret,
  <span class="dt">importance =</span> <span class="st">&quot;impurity&quot;</span>,
  <span class="dt">num.trees =</span> <span class="dv">500</span>
  )

model_caret</code></pre>
<pre><code>## Random Forest 
## 
## 3565 samples
##   29 predictor
##    2 classes: &#39;bad&#39;, &#39;good&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 2851, 2852, 2852, 2852, 2853 
## Resampling results across tuning parameters:
## 
##   mtry  splitrule   min.node.size  ROC        Sens       Spec     
##    1    extratrees  1              0.7891988  0.0000000  1.0000000
##    1    extratrees  3              0.7876724  0.0000000  1.0000000
##    1    extratrees  5              0.7899745  0.0000000  1.0000000
##    1    gini        1              0.8215118  0.0000000  1.0000000
##    1    gini        3              0.8208377  0.0000000  1.0000000
##    1    gini        5              0.8192741  0.0000000  1.0000000
##    4    extratrees  1              0.8040691  0.4074179  0.9219047
##    4    extratrees  3              0.8041195  0.4173781  0.9183914
##    4    extratrees  5              0.8047283  0.4103881  0.9203414
##    4    gini        1              0.8296663  0.4482388  0.9215141
##    4    gini        3              0.8299291  0.4522289  0.9215133
##    4    gini        5              0.8308536  0.4542239  0.9250297
##    7    extratrees  1              0.8046291  0.4522338  0.9094055
##    7    extratrees  3              0.8063292  0.4512239  0.9082343
##    7    extratrees  5              0.8083740  0.4562139  0.9078445
##    7    gini        1              0.8274552  0.4801095  0.9125358
##    7    gini        3              0.8271239  0.4850846  0.9078483
##    7    gini        5              0.8297186  0.4801045  0.9109718
##   10    extratrees  1              0.8057941  0.4701791  0.9078437
##   10    extratrees  3              0.8074283  0.4661542  0.9058906
##   10    extratrees  5              0.8098395  0.4651791  0.9090148
##   10    gini        1              0.8272193  0.5020299  0.9035545
##   10    gini        3              0.8271979  0.4910647  0.9058967
##   10    gini        5              0.8289744  0.4970348  0.9039443
##   13    extratrees  1              0.8065994  0.4681542  0.9031593
##  [ reached getOption(&quot;max.print&quot;) -- omitted 5 rows ]
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were mtry = 4, splitrule = gini
##  and min.node.size = 5.</code></pre>
<p><code>Caret</code> also comes with built-in handy functions for assessing model’s individual predictors strength. By setting the <code>importance = &quot;impurity&quot;</code> in the <code>ranger</code> engine we ensure that variable importance will be returned by the final train object. As of now there is no such possibility in the <code>tidymodels</code> packages and I’m curious to see how it will be solved!</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Accessing most predictive attributes from caret </span>
<span class="kw">varImp</span>(model_caret, <span class="dt">scale =</span> <span class="ot">TRUE</span>)<span class="op">$</span>importance <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rownames_to_column</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>Overall)</code></pre>
<pre><code>##                           rowname    Overall
## 1                          income 100.000000
## 2                       seniority  96.553085
## 3                          amount  87.403163
## 4                           price  80.094041
## 5                             age  66.985275
## 6                          assets  65.523351
## 7                      records_no  49.543132
## 8                        expenses  49.329710
## 9                     records_yes  46.802153
## 10                           time  34.894449
## 11                    job_partime  31.038063
## 12                      job_fixed  29.243620
## 13                           debt  22.225013
## 14                     home_owner  18.784470
## 15                      home_rent  12.899322
## 16                  job_freelance  10.660324
## 17                     home_other   9.827716
## 18                   home_parents   9.616754
## 19                marital_married   9.103606
## 20                 marital_single   7.485771
## 21    marital_infrequent_combined   6.411147
## 22                      home_priv   5.263018
## 23        job_infrequent_combined   3.994922
## 24       home_infrequent_combined   1.431941
## 25    home_unrecorded_observation   0.000000
## 26 marital_unrecorded_observation   0.000000
## 27    records_infrequent_combined   0.000000
## 28 records_unrecorded_observation   0.000000
## 29     job_unrecorded_observation   0.000000</code></pre>
<p>Final cross-validated and test results are easily available with just a couple lines of code. Note that cross-validation performance is aggregated per each index (observation) and averaged out before the final performance metric is calculated.</p>
<p>Getting the test performance is a matter of <code>baking</code> the test set with the already prepped recipe and then making the prediction using the train object. 83.1% AUC for cross-validated training performance and 82.1% for testing - not a bad result for so little preprocessing! Close results also suggest that our model is likely to generalize well to new samples.</p>
<pre class="sourceCode r"><code class="sourceCode r">df_train_pred_caret &lt;-<span class="st"> </span>model_caret<span class="op">$</span>pred <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(rowIndex) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">bad =</span> <span class="kw">mean</span>(bad)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">estimate =</span> bad) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_column</span>(<span class="dt">truth =</span> df_train<span class="op">$</span>status)

<span class="co"># Cross-validated training performance</span>
<span class="kw">percent</span>(<span class="kw">roc_auc</span>(df_train_pred_caret, truth, estimate)<span class="op">$</span>.estimate)</code></pre>
<pre><code>## [1] &quot;83.1%&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">df_test_pred_caret &lt;-<span class="st"> </span><span class="kw">predict</span>(
    model_caret,
    <span class="dt">newdata =</span> <span class="kw">bake</span>(recipe_preped, df_test),
    <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">estimate =</span> bad) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_column</span>(<span class="dt">truth =</span> df_test<span class="op">$</span>status)

<span class="co"># Test performance</span>
<span class="kw">percent</span>(<span class="kw">roc_auc</span>(df_test_pred_caret, truth, estimate)<span class="op">$</span>.estimate)</code></pre>
<pre><code>## [1] &quot;82.1%&quot;</code></pre>
</div>
<div id="tidymodels" class="section level2">
<h2>Tidymodels</h2>
<p>In the beginning, when I saw some of the very first articles about doing ML the tidy way by combining <code>recipes</code> and <code>rsample</code> my thoughts were that it was all way too complicated compared to what <code>caret</code> offered. I was very surprised now when I discovered how clean and simple it became over the last year, and apparently things will be further simplified over the next months (<a href="https://github.com/tidymodels/parsnip/issues/200">link</a>)!</p>
<p>First let’s define two helper functions that will be used later during the modelling process. I imagine these might be wrapped into predefined helper functions in <code>tidymodels</code> packages instead of having to do that every time.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Defining helper functions that will be used later on</span>
fit_on_fold &lt;-<span class="st"> </span><span class="cf">function</span>(spec, prepped) {
  
  x &lt;-<span class="st"> </span><span class="kw">juice</span>(prepped, <span class="kw">all_predictors</span>())
  y &lt;-<span class="st"> </span><span class="kw">juice</span>(prepped, <span class="kw">all_outcomes</span>())
  
  <span class="kw">fit_xy</span>(spec, x, y)
}

predict_helper &lt;-<span class="st"> </span><span class="cf">function</span>(split, recipe, fit) {
  
  new_x &lt;-<span class="st"> </span><span class="kw">bake</span>(recipe, <span class="dt">new_data =</span> <span class="kw">assessment</span>(split), <span class="kw">all_predictors</span>())
  
  <span class="kw">predict</span>(fit, new_x, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">bind_cols</span>(<span class="kw">assessment</span>(split) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(status)) 
}</code></pre>
<p>First, let’s use <code>parsnip</code> to define our ‘modelling engine’ - just like before we’re setting it as a classification problem, using Random Forest running on the <code>ranger</code> engine. On top of that I’m using <code>dials</code> to define a grid of parameters to optimize. <code>Dials</code> provides a set of handy functions, such as: <code>grid_random</code> or <code>grid_regular</code>, that let you choose the range of parameters in a very flexible way.</p>
<p>From what I can see the parameters that could be optimized slightly differ between both frameworks: <code>caret</code> allows for tunning the ‘min.node.size’ while keeping the ‘trees’ constant, while <code>parsnip</code> allows for tuning ‘trees’ while keeping ‘min.node.size’ constant (I assume it’s using the default <code>ranger</code> values). Nevertheless, the total amount of combinations is same in both cases and equal to 30.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Specifying the modelling engine</span>
(engine_tidym &lt;-<span class="st"> </span><span class="kw">rand_forest</span>(<span class="dt">mode =</span> <span class="st">&quot;classification&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;ranger&quot;</span>))</code></pre>
<pre><code>## Random Forest Model Specification (classification)
## 
## Computational engine: ranger</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Specifying the grid of hyperparameters that should be tested</span>
(gridy_tidym &lt;-<span class="st"> </span><span class="kw">grid_random</span>(
  mtry <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">range_set</span>(<span class="kw">c</span>( <span class="dv">1</span>,  <span class="dv">20</span>)),
  trees <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">range_set</span>(<span class="kw">c</span>( <span class="dv">500</span>, <span class="dv">1000</span>)), 
  min_n <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">range_set</span>(<span class="kw">c</span>(<span class="dv">2</span>,  <span class="dv">10</span>)),
  <span class="dt">size =</span> <span class="dv">30</span>
  ))</code></pre>
<pre><code>## # A tibble: 30 x 3
##     mtry trees min_n
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;
##  1     1   806     4
##  2     6   681     6
##  3     7   589     2
##  4     3   923     6
##  5     4   822     5
##  6    19   681    10
##  7     5   572     3
##  8     2   744     2
##  9    12   903     5
## 10    16   616     3
## # … with 20 more rows</code></pre>
<p>Now comes the really interesting part of <code>tidymodels</code>: we’re using a <code>merge</code> helper function from <code>dials</code> to bind our predefined ‘modelling engine’ with all grid combinations of the hyperparameters to tune.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">merge</span>(engine_tidym, gridy_tidym)[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="co"># just to see the top 3</span></code></pre>
<pre><code>## [[1]]
## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = 1
##   trees = 806
##   min_n = 4
## 
## Computational engine: ranger 
## 
## 
## [[2]]
## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = 6
##   trees = 681
##   min_n = 6
## 
## Computational engine: ranger 
## 
## 
## [[3]]
## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = 7
##   trees = 589
##   min_n = 2
## 
## Computational engine: ranger</code></pre>
<p>Subsequently, I’m putting it into a tidy data frame structure where each model-parameters combination is bound together and assigned a model id that will be used later to make a distinction between consequtive fits.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Merging all possibilities with our cross-validated data frame</span>
(spec_tidym &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">spec =</span> <span class="kw">merge</span>(engine_tidym, gridy_tidym)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model_id =</span> <span class="kw">row_number</span>()))</code></pre>
<pre><code>## # A tibble: 30 x 2
##    spec      model_id
##    &lt;list&gt;       &lt;int&gt;
##  1 &lt;spec[+]&gt;        1
##  2 &lt;spec[+]&gt;        2
##  3 &lt;spec[+]&gt;        3
##  4 &lt;spec[+]&gt;        4
##  5 &lt;spec[+]&gt;        5
##  6 &lt;spec[+]&gt;        6
##  7 &lt;spec[+]&gt;        7
##  8 &lt;spec[+]&gt;        8
##  9 &lt;spec[+]&gt;        9
## 10 &lt;spec[+]&gt;       10
## # … with 20 more rows</code></pre>
<p>Lastly, I’m adding the last component into this tidy structure: all cross-validation splits that were specified before with the use of the <code>crossing</code> function. This part is very likely to evolve and be simplified in the upcoming months. Now we’re all set to start the actual tidy-modelling!</p>
<pre class="sourceCode r"><code class="sourceCode r">(spec_tidym &lt;-<span class="st"> </span><span class="kw">crossing</span>(train_cv, spec_tidym))</code></pre>
<pre><code>## # A tibble: 150 x 4
##    splits             id    spec      model_id
##    &lt;named list&gt;       &lt;chr&gt; &lt;list&gt;       &lt;int&gt;
##  1 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        1
##  2 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        2
##  3 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        3
##  4 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        4
##  5 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        5
##  6 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        6
##  7 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        7
##  8 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        8
##  9 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;        9
## 10 &lt;split [2.9K/714]&gt; Fold1 &lt;spec[+]&gt;       10
## # … with 140 more rows</code></pre>
<p>To speed thigs up let’s use the <code>furrr</code> package and fit many models simultaneously. In the following code our original recipe is first prepped on each split’s training set and than it’s used by the <code>fit_on_fold</code> helper function to fit a given model-parameter combination.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fitting each model-fold pair</span>
fits_tidym &lt;-<span class="st"> </span>spec_tidym <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">prepped =</span> <span class="kw">future_map</span>(splits, prepper, recipe),
    <span class="dt">fit =</span> <span class="kw">future_map2</span>(spec, prepped, fit_on_fold)
  )</code></pre>
<p>The last step of modelling involves usage of the other <code>predict_helper</code> function that bakes the already prepped split’s recipe and applies it on the testing set of the split, in order to make a prediction of the given model-parameters combination.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Making predictions of each fitted model on the testing set</span>
fits_pred_tidym &lt;-<span class="st"> </span>fits_tidym <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">preds =</span> <span class="kw">future_pmap</span>(<span class="kw">list</span>(splits, prepped, fit), predict_helper)
  )</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Top row of the entire structure as example</span>
fits_pred_tidym[<span class="dv">1</span>, ]</code></pre>
<pre><code>## # A tibble: 1 x 7
##   splits          id    spec     model_id prepped    fit     preds         
## * &lt;named list&gt;    &lt;chr&gt; &lt;list&gt;      &lt;int&gt; &lt;named li&gt; &lt;list&gt;  &lt;named list&gt;  
## 1 &lt;split [2.9K/7… Fold1 &lt;spec[+…        1 &lt;recipe&gt;   &lt;fit[+… &lt;tibble [714 …</code></pre>
<p>After training is done I would like to assess which model performs the best based on cross-validated hold-out performance. In order to do that, let’s calculate the AUC of all test sets across all model-parameter combinations. By averaging the results up, I can see the entire performance profile of all possibilities.</p>
<p><code>Tidymodels</code> includes also two very handy packages: <a href="https://tidymodels.github.io/probably/index.html">probably</a> and <a href="https://tidymodels.github.io/tidyposterior/">tidyposterior</a>, which are very usefull for analysing model estimated probabilities and it’s resampled performance profile. I will make an introduction to those packages in one of my next posts.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Assessing individual model-fold performance and averaging performance across all folds for each model</span>
(perf_summary_tidym &lt;-<span class="st"> </span>fits_pred_tidym <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>(preds) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(id, model_id) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">roc_auc</span>(<span class="dt">truth =</span> status, .pred_bad) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(model_id, .metric, .estimator) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(.estimate, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>mean)</code></pre>
<pre><code>## # A tibble: 30 x 4
## # Groups:   model_id, .metric [30]
##    model_id .metric .estimator  mean
##       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;
##  1        5 roc_auc binary     0.831
##  2       21 roc_auc binary     0.831
##  3        4 roc_auc binary     0.831
##  4        2 roc_auc binary     0.830
##  5       14 roc_auc binary     0.830
##  6       29 roc_auc binary     0.830
##  7        7 roc_auc binary     0.830
##  8       27 roc_auc binary     0.830
##  9       28 roc_auc binary     0.829
## 10        8 roc_auc binary     0.829
## # … with 20 more rows</code></pre>
<p>Just by sorting the previous results we can easly see what is the best performing model. Let’s now take a step back and filter only that model specification, and fit it on the entire training set. As of now I’m not 100% sure what the recommended and most efficient way of doing that would be, but I decided to go for something like that:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Selecting the best model with:</span>
<span class="co"># perf_summary_tidym$model_id[which.max(perf_summary_tidym$mean)]</span>

<span class="co"># Fitting the best model on the full training set</span>
(model_tidym &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">spec =</span> <span class="kw">merge</span>(engine_tidym, gridy_tidym)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model_id =</span> <span class="kw">row_number</span>()) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(model_id <span class="op">==</span><span class="st"> </span>perf_summary_tidym<span class="op">$</span>model_id[<span class="kw">which.max</span>(perf_summary_tidym<span class="op">$</span>mean)]) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">pull</span>(spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>.[[<span class="dv">1</span>]] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">fit</span>(status <span class="op">~</span><span class="st"> </span>., <span class="kw">juice</span>(recipe_preped)))</code></pre>
<pre><code>## parsnip model object
## 
## Ranger result
## 
## Call:
##  ranger::ranger(formula = formula, data = data, mtry = ~4L, num.trees = ~822L,      min.node.size = ~5L, num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) 
## 
## Type:                             Probability estimation 
## Number of trees:                  822 
## Sample size:                      3565 
## Number of independent variables:  29 
## Mtry:                             4 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        gini 
## OOB prediction error (Brier s.):  0.1431664</code></pre>
<p>Similarly like before with <code>caret</code>, I can now summarize our cross-validated and test performances.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Cross-validated training performance&quot;</span>
<span class="kw">percent</span>(perf_summary_tidym<span class="op">$</span>mean[<span class="kw">which.max</span>(perf_summary_tidym<span class="op">$</span>mean)])</code></pre>
<pre><code>## [1] &quot;83.1%&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Test performance</span>
df_train_pred_tidym &lt;-<span class="st"> </span><span class="kw">predict</span>(
  model_tidym, 
  <span class="dt">new_data =</span> <span class="kw">bake</span>(recipe_preped, df_test), 
  <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">estimate =</span> .pred_bad) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_column</span>(<span class="dt">truth =</span> df_test<span class="op">$</span>status)

<span class="kw">percent</span>(<span class="kw">roc_auc</span>(df_train_pred_tidym, truth, estimate)<span class="op">$</span>.estimate)</code></pre>
<pre><code>## [1] &quot;82.2%&quot;</code></pre>
<p>The entire <code>tidymodels</code> code that was scattered across above sections could be easily squeezed in one longer pipeline. Note that I limited the grid to just one row <code>gridy_tidym[1, ]</code> in order to demonstrate the solution and save on processing time.</p>
<pre class="sourceCode r"><code class="sourceCode r">df_tidym &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">spec =</span> <span class="kw">merge</span>(engine_tidym, gridy_tidym[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, ])) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model_id =</span> <span class="kw">row_number</span>()) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">crossing</span>(train_cv, .) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">prepped =</span> <span class="kw">future_map</span>(splits, prepper, recipe),
    <span class="dt">fit =</span> <span class="kw">future_map2</span>(spec, prepped, fit_on_fold),
    <span class="dt">preds =</span> <span class="kw">future_pmap</span>(<span class="kw">list</span>(splits, prepped, fit), predict_helper)
  )</code></pre>
</div>
</div>
<div id="wrapping-up" class="section level1">
<h1>Wrapping up</h1>
<p>I’ve fit a credit scoring classification Random Forest model using both <code>caret</code> and <code>tidymodels</code> frameworks. I need to admit that before I started writing this post I expected a lot more additional code to be written in the <code>tidymodels</code> framework to achieve the same goal, but to my surprise those packages already offer a very concise (and tidy!) way of doing ML in R, and things will be even more streamlined in the upcoming months. That’s definitely a really big step-up for the entire R community when it comes to doing ML in R. I think R users can expect most of the releases happening still this year and a bigger announcement on <code>tidymodels</code> taking place during the upcoming R Conference in SF in January 2020.</p>
<p>As long it’s already quite nice &amp; easy to use <code>tidymodels</code> as your main ML tool in R, I probably wouldn’t recommend incorporating it in your day-to-day work as it’s still quite unstable, however, I’m definitely looking forward to do that in some time in the future!</p>
</div>
<div id="future-considerations" class="section level1">
<h1>Future considerations</h1>
<ol style="list-style-type: decimal">
<li><p>I still haven’t fully explored the <code>tidyposterior</code> and <code>probably</code> packages - I will do that in one of me next posts.</p></li>
<li><p>On the `<code>rsample</code> page there’s an interesting article listed on so called: <a href="https://tidymodels.github.io/rsample/articles/Applications/Nested_Resampling.html">nested resampling</a>. I’ve never used it in practice but I’m curious to check it out and compare my model’s current cross-validated performance estimate with the one obtained through nested resampling.</p></li>
<li><p>There’s also a lot of buzz in the R community regarding a BETA release of the successor of the <code>mlr</code> package (second most popular ML framework in R) - <a href="https://mlr-org.com/docs/mlr3-0-1-0/">mlr3</a>. <code>mlr3</code> could be very strong competition to the <code>tidymodels</code> framework, and since I’ve never really used <code>mlr</code> it’s an excellent opportunity to put it to a test. It is also modular in design like <code>tidymodels</code>, but is built on top of data.table and uses R6 object-oriented class system which could give it substantial speed advantage over <code>tidymodels</code> at the expenses of ‘tidyness’.</p></li>
</ol>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="/tags/caret/">caret</a>

  <a class="tag tag--primary tag--small" href="/tags/tidymodels/">tidymodels</a>

  <a class="tag tag--primary tag--small" href="/tags/predictive-modelling/">predictive modelling</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/08/caret-vs-tidymodels-comparing-the-old-and-new/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/08/caret-vs-tidymodels-comparing-the-old-and-new/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 Konrad Semsch. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/08/caret-vs-tidymodels-comparing-the-old-and-new/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/08/caret-vs-tidymodels-comparing-the-old-and-new/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2019%2F08%2Fcaret-vs-tidymodels-comparing-the-old-and-new%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2019%2F08%2Fcaret-vs-tidymodels-comparing-the-old-and-new%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="/images/profile.png" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Konrad Semsch</h4>
    
      <div id="about-card-bio">Practitioners view on predictive modelling</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Senior Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Dortmund, Germany
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/08/caret-vs-tidymodels-comparing-the-old-and-new/">
                <h3 class="media-heading">Caret vs. tidymodels - comparing the old and new</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style>
body {
text-align: justify}
</style>
<p>In this post I will make a comparison between the most popular (by number of monthly downloads from Github) ML framework available for R to date: caret and its successor packages being written by the same author (Max Kuhn) that are wrapped together in a so called tidymodels framework.</p>
</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         1 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://res.cloudinary.com/dl7yqljrx/image/upload/v1538116337/background_small.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2019\/08\/caret-vs-tidymodels-comparing-the-old-and-new\/';
          
            this.page.identifier = '\/2019\/08\/caret-vs-tidymodels-comparing-the-old-and-new\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'hugo-tranquilpeak-theme';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>




  
    
  


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.56.3">
    <title>Testing the new tidymodels&#39; tune package - empirical analysis between the oversampling ratio value and model performance</title>
    <meta name="author" content="Konrad Semsch">
    <meta name="keywords" content=", data science, statistics, machine learning, predictive modelling, fintech, banking, r">

    <link rel="icon" href="/favicon.png">
    

    
    <meta name="description" content="




Have you ever also found yourself in a situation in which you were dealing with an imbalanced, classification problem but you weren’t really quite sure how much imbalance is ‘good’? Or what’s the relation of the correcting the imbalance with model performance? In this post I will explore the relationship between the upsampling ratio and model performance while using the brand new tidymodels’ tune package.
">
    <meta property="og:description" content="




Have you ever also found yourself in a situation in which you were dealing with an imbalanced, classification problem but you weren’t really quite sure how much imbalance is ‘good’? Or what’s the relation of the correcting the imbalance with model performance? In this post I will explore the relationship between the upsampling ratio and model performance while using the brand new tidymodels’ tune package.
">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Testing the new tidymodels&#39; tune package - empirical analysis between the oversampling ratio value and model performance">
    <meta property="og:url" content="/2019/10/testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance/">
    <meta property="og:site_name" content="Practitioners view on predictive modelling">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Practitioners view on predictive modelling">
    <meta name="twitter:description" content="




Have you ever also found yourself in a situation in which you were dealing with an imbalanced, classification problem but you weren’t really quite sure how much imbalance is ‘good’? Or what’s the relation of the correcting the imbalance with model performance? In this post I will explore the relationship between the upsampling ratio and model performance while using the brand new tidymodels’ tune package.
">
    
    

    
    

    
      <meta property="og:image" content="/images/profile.png">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-146680003-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">Practitioners view on predictive modelling</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="/images/profile.png" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="/images/profile.png" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Konrad Semsch</h4>
        
          <h5 class="sidebar-profile-bio">Practitioners view on predictive modelling</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <b><i class="sidebar-button-icon fa fa-lg fa-home"></i></b>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.linkedin.com/in/konradsemsch/">
    
      <i class="sidebar-button-icon fa fa-linkedin-square"></i>
      
      <span class="sidebar-button-desc">Linkedin</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/konradsemsch">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Testing the new tidymodels&#39; tune package - empirical analysis between the oversampling ratio value and model performance
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-10-11T00:00:00Z">
        
  
  
  
  
    11 October 2019
  

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/predictive-modelling">predictive modelling</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <p>Have you ever also found yourself in a situation in which you were dealing with an imbalanced, classification problem but you weren’t really quite sure how much imbalance is ‘good enough’? Or what’s the relation between correcting the imbalance and model performance/ form? In this post I will explore the relationship between the upsampling ratio and model performance while using the brand new <code>tidymodels</code> <a href="https://tidymodels.github.io/tune/">tune</a> package.</p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>First, let’s start with a short introduction into the topic. Why should we account for class imbalance when working on a model? The main reason for this is: &quot;&quot; &lt;- put a quote from Max Kuhn’s book. Max lists also a number of other different methods that could be used in the course of modelling in order to combat class imbalance but in this post I will not focus on covering all of them - upsamling. Of course the selection of the most appropriate method depends on the specific modelling task, but at the end of the day, regardless of the methodlogy used the</p>
<p>Coming back to the main question: what is the best value of the ratio to balance both target classes? Intuitively, it would be one that makes both classes equally frequent, but on the other hand have you ever checked the impact of using different ratio on your model performance/ form? Wouldn’t it be great if we could easily simulate that and get all the results at hand? Thankfully we can easily do that with the use of the latest addition to the [tidymodels][<a href="https://github.com/tidymodels" class="uri">https://github.com/tidymodels</a>] stack called <a href="https://tidymodels.github.io/tune/">tune</a>.</p>
</div>
<div id="a-bit-of-theory" class="section level1">
<h1>A bit of theory</h1>
<p>I’ve wanted to write this post for a really long time because I’ve never found a direct and comprehensive answer to this question before. Some of the more interesting resources that I came across online say the following:</p>
<ol style="list-style-type: decimal">
<li><a href="https://www.svds.com/learning-imbalanced-classes/">original discussion with Max</a> -</li>
<li><a href="https://xgboost.readthedocs.io/en/latest/parameter.html">xgboost docs</a> -</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html">scikit-learn docs</a> -</li>
<li><a href="https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras">ds-stackexchange</a> -</li>
<li><a href="https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data">google-developers</a> -</li>
<li><a href="https://www.svds.com/learning-imbalanced-classes/">svds</a> -</li>
</ol>
<p>Once equiped with some preliminary theory let’s dive into our simulation and see the effects ourselves!</p>
</div>
<div id="initial-setup" class="section level1">
<h1>Initial setup</h1>
<p>Please not that most of those <code>tidymodels</code> packages are still unstable and subject to change. It’s likely that in a couple weeks/ months time parts of this could would not execute. I will try to keep it up to date, but nevertheless, the outcomes of the simulation will still hold true.</p>
<p>First let’s install and load all required packages. Remember that <code>tune</code> is for now only distributed as a development version available from github.</p>
<p>One of the vignettes of <code>tune</code> suggests to parallelize computations while finding for optimal hyperparameter values. We can achieve that by using the <code>doFuture</code> package below.</p>
<pre class="sourceCode r"><code class="sourceCode r">
all_cores &lt;-<span class="st"> </span>parallel<span class="op">::</span><span class="kw">detectCores</span>(<span class="dt">logical =</span> <span class="ot">FALSE</span>)

<span class="kw">registerDoFuture</span>()
cl &lt;-<span class="st"> </span><span class="kw">makeCluster</span>(all_cores)
<span class="kw">plan</span>(cluster, <span class="dt">workers =</span> cl)</code></pre>
<p>In our simulation I decided to use the <code>credit_data</code> dataset available in the <a href="">recipes</a> package, which depicts a well-known clasisfication class imbalanced problem of defaulted vs. non-defaulted loans.</p>
<pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">data</span>(<span class="st">&quot;credit_data&quot;</span>)

credit_data <span class="op">%&lt;&gt;%</span>
<span class="st">  </span><span class="kw">set_names</span>(., <span class="kw">tolower</span>(<span class="kw">names</span>(.)))</code></pre>
<p>In this specific example the severerity of class imbalance is actually pretty low and it probably would be also acceptable if it was disregarded, however, applying any rebalancing technique will surelely improve the model form. Let’s find out!</p>
<pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">round</span>(<span class="kw">prop.table</span>(<span class="kw">table</span>(credit_data<span class="op">$</span>status)), <span class="dv">2</span>)
<span class="co">## </span>
<span class="co">##  bad good </span>
<span class="co">## 0.28 0.72</span></code></pre>
<p>Note that apart from regular train/ test splits I also decided to repeat the CV process three times. The dataset isn’t particularly big so we can get more stable and reliable results by performing the CV process more than once.</p>
<pre class="sourceCode r"><code class="sourceCode r">
split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(credit_data, <span class="dt">prop =</span> <span class="fl">0.80</span>, <span class="dt">strata =</span> <span class="st">&quot;status&quot;</span>)

df_train &lt;-<span class="st"> </span><span class="kw">training</span>(split)
df_test  &lt;-<span class="st"> </span><span class="kw">testing</span>(split)

train_cv &lt;-<span class="st"> </span><span class="kw">vfold_cv</span>(df_train, <span class="dt">v =</span> <span class="dv">5</span>, <span class="dt">repeats =</span> <span class="dv">3</span>, <span class="dt">strata =</span> <span class="st">&quot;status&quot;</span>)</code></pre>
</div>
<div id="model-specification" class="section level1">
<h1>Model specification</h1>
<p>I will use <a href="">parsnip</a> as the main modelling engine and decided to train a regular Random Forest model. I wanted to select a model that has already embedded regularization, but doesn’t require a lot hyperparameter tuning to provide a good solution. The reason for that was that this time we need to keep our model parameters constant and tune the value of oversampling - otherwise our results would not be comparable.</p>
<pre class="sourceCode r"><code class="sourceCode r">
(engine &lt;-<span class="st"> </span><span class="kw">rand_forest</span>(
  <span class="dt">mtry =</span> <span class="dv">2</span>,
  <span class="dt">trees =</span> <span class="dv">500</span>, 
  <span class="dt">min_n =</span> <span class="dv">10</span>
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">set_engine</span>(<span class="st">&quot;ranger&quot;</span>))
<span class="co">## Random Forest Model Specification (classification)</span>
<span class="co">## </span>
<span class="co">## Main Arguments:</span>
<span class="co">##   mtry = 2</span>
<span class="co">##   trees = 500</span>
<span class="co">##   min_n = 10</span>
<span class="co">## </span>
<span class="co">## Computational engine: ranger</span></code></pre>
<p>The next step is the specify our modelling recipe. It’s a pretty standard one that definitely
could be further modified to improve model performance, but one thing is definitely worth
point out - the usage of <code>tune()</code> in the last line. It’s currently a placeholder for a set of candidate values that will need to be evaluated. That’s how we can pass an information
to our recipe/ model tuning process about a parameter that will need to be optimized during fitting.</p>
<pre class="sourceCode r"><code class="sourceCode r">
recipe &lt;-<span class="st"> </span>df_train <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">recipe</span>(status <span class="op">~</span><span class="st"> </span>.) <span class="op">%&gt;%</span>

<span class="st">  </span><span class="co"># Imputation: assigning NAs to a new level for categorical </span>
<span class="st">  </span><span class="co"># (that&#39;s good practice, but not needed here) and median imputation for numeric</span>
<span class="st">  </span><span class="kw">step_unknown</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span>status) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">step_medianimpute</span>(<span class="kw">all_numeric</span>()) <span class="op">%&gt;%</span>

<span class="st">  </span><span class="co"># Combining infrequent categorical levels and introducing a new level </span>
<span class="st">  </span><span class="co"># for prediction time (that&#39;s good practice, but not needed here)</span>
<span class="st">  </span><span class="kw">step_other</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span>status, <span class="dt">other =</span> <span class="st">&quot;infrequent_combined&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_novel</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span>status, <span class="dt">new_level =</span> <span class="st">&quot;unrecorded_observation&quot;</span>) <span class="op">%&gt;%</span>

<span class="st">  </span><span class="co"># Hot-encoding categorical variables</span>
<span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span>status, <span class="dt">one_hot =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># Creating additional ratio variables - they typically make sense </span>
<span class="st">  </span><span class="co"># in credit scoring problems</span>
<span class="st">  </span><span class="kw">step_mutate</span>(
    <span class="dt">ratio_expenses_income =</span> expenses <span class="op">/</span><span class="st"> </span>(income <span class="op">+</span><span class="st"> </span><span class="fl">0.001</span>),
    <span class="dt">ratio_assets_income =</span> assets <span class="op">/</span><span class="st"> </span>(income <span class="op">+</span><span class="st"> </span><span class="fl">0.001</span>),
    <span class="dt">ratio_debt_income =</span> debt <span class="op">/</span><span class="st"> </span>(income <span class="op">+</span><span class="st"> </span><span class="fl">0.001</span>),
    <span class="dt">ratio_debt_assets =</span> debt <span class="op">/</span><span class="st"> </span>(assets <span class="op">+</span><span class="st"> </span><span class="fl">0.001</span>),
    <span class="dt">ratio_amout_price =</span> amount <span class="op">/</span><span class="st"> </span>(price <span class="op">+</span><span class="st"> </span><span class="fl">0.001</span>)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># Adding upsampling </span>
<span class="st">  </span><span class="kw">step_upsample</span>(status, <span class="dt">over_ratio =</span> <span class="kw">tune</span>())</code></pre>
<p>Now I’m using the <a href="">dials</a> package to create a grid of candidates of over-sampling ratio values that will be evaluated during model fitting. Based on <code>recipes::step_upsample()</code> documentation we can see that an over-sampling ratio value equal to 1 means that all levels are sampled to have the same frequency. A value of 0.5 would mean that the minority class will be half as frequent as the minority class (approximately).</p>
<pre class="sourceCode r"><code class="sourceCode r">
(grid &lt;-<span class="st"> </span><span class="kw">grid_regular</span>(
  <span class="kw">over_ratio</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">range_set</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">1.5</span>)),
  <span class="dt">levels =</span> <span class="dv">11</span>
  ))
<span class="co">## # A tibble: 11 x 1</span>
<span class="co">##    over_ratio</span>
<span class="co">##         &lt;dbl&gt;</span>
<span class="co">##  1        0.5</span>
<span class="co">##  2        0.6</span>
<span class="co">##  3        0.7</span>
<span class="co">##  4        0.8</span>
<span class="co">##  5        0.9</span>
<span class="co">##  6        1  </span>
<span class="co">##  7        1.1</span>
<span class="co">##  8        1.2</span>
<span class="co">##  9        1.3</span>
<span class="co">## 10        1.4</span>
<span class="co">## 11        1.5</span></code></pre>
<p>Let’s move to the final step of connecting all previously specified inputs: our recipe, model engine, resampled train/ test sets and grid of candidate values to evaluate. On top of that we pass which metrics we would like to track for each iteration using the <a href="">yardstick</a> package, as well as disable verbosity of the procedure. Note that in the <code>grid_control</code> function call parallel processing is enabled by default if a parellel backend was previously registered.</p>
<p>Nevertheless, please keep in mind that this code chunk will most probably run for a couple of minutes before all models will be fitted.</p>
<pre class="sourceCode r"><code class="sourceCode r">
fits &lt;-<span class="st"> </span><span class="kw">tune_grid</span>(
  recipe,
  <span class="dt">model =</span> engine,
  <span class="dt">rs =</span> train_cv,
  <span class="dt">grid =</span> grid,
  <span class="dt">perf =</span> <span class="kw">metric_set</span>(roc_auc, j_index, sens, spec),
  <span class="dt">control =</span> <span class="kw">grid_control</span>(<span class="dt">verbose =</span> <span class="ot">FALSE</span>)
)</code></pre>
<p>The outcome of the <code>tune_grid</code> function is a tidy, nested tibble object separated by CV repetition and each hold-out fold performance metrics specified before.</p>
<pre class="sourceCode r"><code class="sourceCode r">
fits
<span class="co">## #  5-fold cross-validation repeated 3 times using stratification </span>
<span class="co">## # A tibble: 15 x 5</span>
<span class="co">##    splits             id      id2   .metrics          .notes          </span>
<span class="co">##  * &lt;list&gt;             &lt;chr&gt;   &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          </span>
<span class="co">##  1 &lt;split [2.9K/714]&gt; Repeat1 Fold1 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">##  2 &lt;split [2.9K/713]&gt; Repeat1 Fold2 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">##  3 &lt;split [2.9K/713]&gt; Repeat1 Fold3 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">##  4 &lt;split [2.9K/713]&gt; Repeat1 Fold4 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">##  5 &lt;split [2.9K/712]&gt; Repeat1 Fold5 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">##  6 &lt;split [2.9K/714]&gt; Repeat2 Fold1 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">##  7 &lt;split [2.9K/713]&gt; Repeat2 Fold2 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">##  8 &lt;split [2.9K/713]&gt; Repeat2 Fold3 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">##  9 &lt;split [2.9K/713]&gt; Repeat2 Fold4 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">## 10 &lt;split [2.9K/712]&gt; Repeat2 Fold5 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">## 11 &lt;split [2.9K/714]&gt; Repeat3 Fold1 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">## 12 &lt;split [2.9K/713]&gt; Repeat3 Fold2 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">## 13 &lt;split [2.9K/713]&gt; Repeat3 Fold3 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">## 14 &lt;split [2.9K/713]&gt; Repeat3 Fold4 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span>
<span class="co">## 15 &lt;split [2.9K/712]&gt; Repeat3 Fold5 &lt;tibble [44 × 4]&gt; &lt;tibble [0 × 1]&gt;</span></code></pre>
<p>It can be further easily summarized with the <code>estimate</code> function, which will extract and flatten the .metrics column. It makes it very convenient to visualize the performance profile of the model.</p>
<pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">estimate</span>(fits) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(over_ratio))
<span class="co">## # A tibble: 44 x 6</span>
<span class="co">##    over_ratio .metric .estimator  mean     n std_err</span>
<span class="co">##         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;</span>
<span class="co">##  1        1.5 j_index binary     0.509    15 0.0104 </span>
<span class="co">##  2        1.5 roc_auc binary     0.837    15 0.00434</span>
<span class="co">##  3        1.5 sens    binary     0.696    15 0.00913</span>
<span class="co">##  4        1.5 spec    binary     0.813    15 0.00464</span>
<span class="co">##  5        1.4 j_index binary     0.512    15 0.0104 </span>
<span class="co">##  6        1.4 roc_auc binary     0.837    15 0.00432</span>
<span class="co">##  7        1.4 sens    binary     0.704    15 0.00908</span>
<span class="co">##  8        1.4 spec    binary     0.809    15 0.00421</span>
<span class="co">##  9        1.3 j_index binary     0.518    15 0.00933</span>
<span class="co">## 10        1.3 roc_auc binary     0.837    15 0.00413</span>
<span class="co">## # … with 34 more rows</span></code></pre>
</div>
<div id="analyzing-performance-profile" class="section level1">
<h1>Analyzing performance profile</h1>
<p>For visualization of the results I will use my own <a href="">ggrapid</a> package that you can install from Github. After having a quick look at the plot we can arrive at the following conclusions:</p>
<pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">library</span>(ggrapid)

<span class="kw">estimate</span>(fits) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">over_ratio =</span> <span class="kw">as.character</span>(over_ratio)
    ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(
    <span class="dt">Metric =</span> .metric  
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot_line</span>(
    over_ratio, 
    mean, 
    <span class="dt">fill =</span> Metric,
    <span class="dt">title =</span> <span class="st">&quot;Performance metrics across different upsampling ratios values&quot;</span>,
    <span class="dt">caption =</span> <span class="st">&quot;Upsampling ratio = 1 - equal number of observations between classes&quot;</span>,
    <span class="dt">lab_x =</span> <span class="st">&quot;Upsampling ratio between both classes&quot;</span>,
    <span class="dt">lab_y =</span> <span class="st">&quot;Performance metric value&quot;</span>,
    <span class="dt">angle =</span> <span class="dv">0</span>,
    <span class="dt">limit_max =</span> <span class="dv">1</span>
    )</code></pre>
<p><img src="/post/2019-10-11-testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<ol style="list-style-type: decimal">
<li><p><strong>ROC AUC</strong> - regardless of the value of the oversampling ratio the overall rank ordering ability of the model remains constant. It makes sense as the ROC AUC is calculated across the entire space of the probability cut-off.</p></li>
<li><p><strong>Sensitivity / specificity</strong> - with a higher value of the oversampling ratio sensitivity increases, while specificity decreases. This shows that even though the overall ability of the model remains constant (point above), it’s inner working and ability to better capture the patterns of the minority class significantly improve. This is precisely what we want to achieve in problems such as credit scoring. The reason for this is that both types of errors have vastly different costs associated to them, and we care much more about not approving true defaults, rather than rejecting true non-defaults.</p></li>
<li><p><strong>J-index</strong> - confirms the previous point as it’s calculated as: sensitivity + specificity - 1. The J-index suggests that the best trade-off between sensitivity and specificity is achieved when the oversampling ratio is equal to 1.1. In practice it means that the frequency of the original minority class is by 10% higher in each model fit iteration than the original majority class.</p></li>
</ol>
<p>The above analysis proves the statement that even though there is no impact of the oversampling ratio value on the ROC AUC, combatting class imbalance has an enourmous impact on how the minority patterns are exposed and eventually learnt by the algorithm. Most software packages and tools by default suggest an oversampling ratio that makes both frequencies equal - it makes a lot of sense and is a reasonable default. What’s surprising though is that (at least for this example) we can see that a value higher than 1 improves the results even further.</p>
</div>
<div id="can-we-trust-upsampled-probabilities" class="section level1">
<h1>Can we trust upsampled probabilities?</h1>
<p>If you thought that’s the end if this post you were wrong. The reason for this is that estimated probabilities from upsampled models can’t be trusted and used directly. Check out the next chunks to find out!</p>
<p>First of all, let’s extract the value of the oversampling ratio that resulted in the best model form. Our goal now is to fit the model again to the entire training set using that best parameter value.</p>
<pre class="sourceCode r"><code class="sourceCode r">
(over_ratio_best &lt;-<span class="st"> </span><span class="kw">estimate</span>(fits) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(.metric <span class="op">==</span><span class="st"> &quot;j_index&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(mean)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">pull</span>(over_ratio))
<span class="co">## [1] 1.3</span></code></pre>
<p>Now we need to update our originally specified recipe using the <code>update</code> function. Perhaps there will be a better way of doing that in the upcoming <code>tidymodels</code> stack, but that was the best method I was able to find at the moment of writing this post.</p>
<pre class="sourceCode r"><code class="sourceCode r">
recipe_best &lt;-<span class="st"> </span>recipe
recipe_best<span class="op">$</span>steps[[<span class="dv">7</span>]] &lt;-<span class="st"> </span><span class="kw">update</span>(recipe<span class="op">$</span>steps[[<span class="dv">7</span>]], <span class="dt">over_ratio =</span> over_ratio_best)</code></pre>
<p>Once we have the recipe updated we <code>prep</code> it, and use <code>fit</code> our previously specified Random Forest engine.</p>
<pre class="sourceCode r"><code class="sourceCode r">
recipe_best_prep &lt;-<span class="st"> </span><span class="kw">prep</span>(recipe_best, <span class="dt">retain =</span> <span class="ot">TRUE</span>)

(fit_best &lt;-<span class="st"> </span>engine <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">fit</span>(status <span class="op">~</span><span class="st"> </span>., <span class="kw">juice</span>(recipe_best_prep)))
<span class="co">## parsnip model object</span>
<span class="co">## </span>
<span class="co">## Ranger result</span>
<span class="co">## </span>
<span class="co">## Call:</span>
<span class="co">##  ranger::ranger(formula = formula, data = data, mtry = ~2, num.trees = ~500,      min.node.size = ~10, num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) </span>
<span class="co">## </span>
<span class="co">## Type:                             Probability estimation </span>
<span class="co">## Number of trees:                  500 </span>
<span class="co">## Sample size:                      6658 </span>
<span class="co">## Number of independent variables:  34 </span>
<span class="co">## Mtry:                             2 </span>
<span class="co">## Target node size:                 10 </span>
<span class="co">## Variable importance mode:         none </span>
<span class="co">## Splitrule:                        gini </span>
<span class="co">## OOB prediction error (Brier s.):  0.1274562</span></code></pre>
<p>And now’s the main point - if no upsampling was performed, we could use that model as is and obtain reliable predictions. But having used a rebalancing technique, the estimated model probabilities follow now a different distribution.</p>
<p>If you recall, the frequency of the minority class was roughly 28%, therefore the average estimated probability should be almost identical. However, the average estimated probability of our model is now <code>0.426041</code>! It means that these probabilities can’t be used by nobody because they have a completely different distribution that our training data. Can we do anything about that?</p>
<pre class="sourceCode r"><code class="sourceCode r">
df_train_pred &lt;-<span class="st"> </span>
<span class="st">  </span>df_train <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(status) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">prob =</span> <span class="kw">predict</span>(fit_best, <span class="kw">bake</span>(recipe_best_prep, df_train), <span class="st">&quot;prob&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">pull</span>(.pred_bad)
  )

<span class="kw">mean</span>(df_train_pred<span class="op">$</span>prob)
<span class="co">## [1] 0.426041</span></code></pre>
</div>
<div id="probabilities-calibration" class="section level1">
<h1>Probabilities calibration</h1>
<p>A very usefull technique that can help us in this situation is called <a href="http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/">Platts scaling</a>. I do not want to get too deep into explaining probabilities calibration in this post, but go ahead and check that link.</p>
<p>However, just to give a high level overview: the point of probabilities calibration is to scale estimated model probabilities back to it’s original distribution (with same or different mean). You can apply probabilities scaling with <code>Platts</code> using the function below that I once implemented in one of my packages.</p>
<pre class="sourceCode r"><code class="sourceCode r">
calibrate_probabilities &lt;-<span class="st"> </span><span class="cf">function</span>(df_pred,
                                    target,
                                    prediction,
                                    <span class="dt">top_level =</span> <span class="st">&quot;1&quot;</span>,
                                    <span class="dt">target_prob =</span> <span class="fl">0.0</span>
                                    ) {

  var_target &lt;-<span class="st"> </span>rlang<span class="op">::</span><span class="kw">enquo</span>(target)
  var_prediction &lt;-<span class="st"> </span>rlang<span class="op">::</span><span class="kw">enquo</span>(prediction)

  df_pred &lt;-<span class="st"> </span>df_pred <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(
      <span class="dt">target =</span> <span class="kw">case_when</span>(
        <span class="op">!!</span>var_target <span class="op">==</span><span class="st"> </span>top_level <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,
        <span class="ot">TRUE</span> <span class="op">~</span><span class="st"> </span><span class="dv">0</span>),
      <span class="dt">score =</span> <span class="kw">round</span>(<span class="dv">100</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>((<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="op">!!</span>var_prediction) <span class="op">/</span><span class="st"> </span><span class="op">!!</span>var_prediction), <span class="dv">0</span>)
      )

  glm &lt;-<span class="st"> </span>stats<span class="op">::</span><span class="kw">glm</span>(target <span class="op">~</span><span class="st"> </span>score, <span class="dt">data =</span> df_pred, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)
  glm_coef &lt;-<span class="st"> </span>glm<span class="op">$</span>coef

  dr &lt;-<span class="st"> </span><span class="kw">nrow</span>(<span class="kw">filter</span>(df_pred, <span class="op">!!</span>var_target <span class="op">==</span><span class="st"> </span>top_level)) <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(df_pred)
  target_prob &lt;-<span class="st"> </span><span class="kw">ifelse</span>(target_prob <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, dr, target_prob)
  k &lt;-<span class="st"> </span>(dr <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>dr)) <span class="op">/</span><span class="st"> </span>(target_prob <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>target_prob)) <span class="co"># final scaling factor</span>

  df_pred <span class="op">%&lt;&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(
      <span class="dt">prediction_scaled =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>(glm_coef[[<span class="dv">1</span>]] <span class="op">+</span><span class="st"> </span>glm_coef[[<span class="dv">2</span>]] <span class="op">*</span><span class="st"> </span>score))) 
    )

  <span class="kw">list</span>(
    <span class="dt">glm_fit =</span> glm,
    <span class="dt">glm_coef =</span> glm_coef,
    <span class="dt">parameters =</span> <span class="kw">list</span>(
      <span class="dt">dr =</span> dr,
      <span class="dt">target_prob =</span> target_prob,
      <span class="dt">k =</span> k
    ),
    <span class="dt">df_calibrated =</span> df_pred
    )

}</code></pre>
<p>Let’s put the function into practice and check the results:</p>
<pre class="sourceCode r"><code class="sourceCode r">
calibration &lt;-<span class="st"> </span><span class="kw">calibrate_probabilities</span>(
  df_train_pred,
  status,
  prob,
  <span class="st">&quot;bad&quot;</span>
)

<span class="kw">mean</span>(calibration<span class="op">$</span>df_calibrated<span class="op">$</span>prediction_scaled)
<span class="co">## [1] 0.2816269</span></code></pre>
<p>Great! We scaled our estimated probabilities back to the original distribution and we’re getting back the original minority class frequency. In case you’re still not convinced, take a look at the comparison of distributions between both estimated probabilities presented below.</p>
<pre class="sourceCode r"><code class="sourceCode r">
df_train_pred <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">version =</span> <span class="st">&quot;uncalibrated&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_rows</span>(
    calibration<span class="op">$</span>df_calibrated <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">select</span>(
        status,
        prediction_scaled
      ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">rename</span>(<span class="dt">prob =</span> prediction_scaled) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">version =</span> <span class="st">&quot;calibrated&quot;</span>)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot_density</span>(
    prob, 
    <span class="dt">fill =</span> version, 
    <span class="dt">title =</span> <span class="st">&quot;Density comparison between calibrated and uncalibrated estimated probabilities&quot;</span>,
    <span class="dt">lab_x =</span> <span class="st">&quot;Estimated probability by the model&quot;</span>,
    <span class="dt">quantile_low =</span> <span class="dv">0</span>,
    <span class="dt">quantile_high =</span> <span class="dv">1</span>
    )</code></pre>
<p><img src="/post/2019-10-11-testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
<div id="wrapping-up" class="section level1">
<h1>Wrapping up</h1>
</div>
<div id="future-considerations" class="section level1">
<h1>Future considerations</h1>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="/tags/tidymodels/">tidymodels</a>

  <a class="tag tag--primary tag--small" href="/tags/predictive-modelling/">predictive modelling</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/08/2019-08-29-ggrapid-create-neat-and-complete-ggplot-visualizations-with-as-little-code-as-possible/" data-tooltip="{ggrapid}: Create neat &amp; complete ggplot visualizations with as little code as possible">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/10/testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/10/testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 Konrad Semsch. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/08/2019-08-29-ggrapid-create-neat-and-complete-ggplot-visualizations-with-as-little-code-as-possible/" data-tooltip="{ggrapid}: Create neat &amp; complete ggplot visualizations with as little code as possible">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/10/testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/10/testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2019%2F10%2Ftesting-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2019%2F10%2Ftesting-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="/images/profile.png" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Konrad Semsch</h4>
    
      <div id="about-card-bio">Practitioners view on predictive modelling</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Senior Data Scientist
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Dortmund, Germany
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/10/testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance/">
                <h3 class="media-heading">Testing the new tidymodels&#39; tune package - empirical analysis between the oversampling ratio value and model performance</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style>
body {
text-align: justify}
</style>
<p>Have you ever also found yourself in a situation in which you were dealing with an imbalanced, classification problem but you weren’t really quite sure how much imbalance is ‘good’? Or what’s the relation of the correcting the imbalance with model performance? In this post I will explore the relationship between the upsampling ratio and model performance while using the brand new tidymodels’ tune package.</p>
</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/08/2019-08-29-ggrapid-create-neat-and-complete-ggplot-visualizations-with-as-little-code-as-possible/">
                <h3 class="media-heading">{ggrapid}: Create neat &amp; complete ggplot visualizations with as little code as possible</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style>
body {
text-align: justify}
</style>
<p>In this post I will make a an introduction to a new data visulazation package that I recently published on Github - <a href="https://github.com/konradsemsch/ggrapid">ggrapid</a>! ggrapid enables creation of the most common ggplot-based visualizations fast and with just a few lines of code.</p>
</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/08/caret-vs-tidymodels-comparing-the-old-and-new/">
                <h3 class="media-heading">Caret vs. tidymodels - comparing the old and new</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style>
body {
text-align: justify}
</style>
<p>In this post I will make a comparison between the most popular (by number of monthly downloads from Github) ML framework available for R to date: caret and its successor packages being written by the same author (Max Kuhn) that are wrapped together in a so called tidymodels framework.</p>
</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         3 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('https://res.cloudinary.com/dl7yqljrx/image/upload/v1538116337/background_small.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2019\/10\/testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance\/';
          
            this.page.identifier = '\/2019\/10\/testing-the-new-tidymodels-tune-package-empirical-analysis-between-the-value-of-oversampling-ratio-and-model-performance\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'konradsemsch';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>


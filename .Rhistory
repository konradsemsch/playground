set_engine("ranger"))
recipe_with_shadow <- data_churn %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_without_shadow <- recipe(churn ~ ., data_churn) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(all_outcomes())
recipe_with_shadow_prep <- prep(recipe_with_shadow, retain = TRUE)
recipe_without_shadow_prep <- prep(recipe_without_shadow, retain = TRUE)
recipe_with_shadow <- df_train %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_without_shadow <- recipe(churn ~ ., df_train) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(all_outcomes())
recipe_with_shadow_prep <- prep(recipe_with_shadow, retain = TRUE)
recipe_without_shadow_prep <- prep(recipe_without_shadow, retain = TRUE)
fit_with_shadow <- fit(churn ~ ., data = juice(recipe_with_shadow_prep))
fit_with_shadow <- engine %>% fit(churn ~ ., data = juice(recipe_with_shadow_prep))
fit_without_shadow <- engine %>% fit(churn ~ ., data = juice(recipe_without_shadow_prep))
fit_with_shadow
pred_with_shadow <- predict(fit_with_shadow, bake(recipe_with_shadow_prep, df_test))
pred_with_shadow
pred_with_shadow <- predict(fit_with_shadow, bake(recipe_with_shadow_prep, df_test), "prob")
pred_without_shadow <- predict(fit_with_shadow, bake(recipe_without_shadow_prep, df_test), "prob")
pred_with_shadow <- predict(fit_with_shadow, bake(recipe_with_shadow_prep, df_test), "prob")
pred_without_shadow <- predict(fit_without_shadow, bake(recipe_without_shadow_prep, df_test), "prob")
library(yardstick)
pred_with_shadow
# roc_auc()
# pred_with_shadow
roc_auc(df_test$churn, pred_with_shadow$.pred_Yes)
?roc_auc()
# pred_with_shadow
roc_auc_vec(df_test$churn, pred_with_shadow$.pred_Yes)
# pred_with_shadow
roc_auc_vec(df_test$churn, pred_with_shadow$.pred_Yes)
roc_auc_vec(df_test$churn, fit_without_shadow$.pred_Yes)
# pred_with_shadow
roc_auc_vec(df_test$churn, pred_with_shadow$.pred_Yes)
roc_auc_vec(df_test$churn, pred_without_shadow$.pred_Yes)
recipe <- df_train %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_prep <- prep(recipe_with_shadow, retain = TRUE)
juice(recipe_with_shadow_prep)
glimpse(juice(recipe_with_shadow_prep))
(engine <- rand_forest(
mtry = 2,
trees = 500,
min_n = 10
) %>%
set_mode("classification") %>%
set_engine("ranger"))
fit_ <- engine %>% fit(churn ~ ., data = juice(recipe_prep))
(engine <- rand_forest(
mtry = 2,
trees = 500,
min_n = 10
) %>%
set_mode("classification") %>%
set_engine("ranger"))
fit <- engine %>%
fit(churn ~ ., data = juice(recipe_prep))
pred <- predict(fit, bake(recipeprep, df_test), "prob")
recipe <- df_train %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_prep <- prep(recipe_with_shadow, retain = TRUE)
glimpse(juice(recipe_with_shadow_prep))
(engine <- rand_forest(
mtry = 2,
trees = 500,
min_n = 10
) %>%
set_mode("classification") %>%
set_engine("ranger"))
fit <- engine %>%
fit(churn ~ ., data = juice(recipe_prep))
pred <- predict(fit, bake(recipeprep, df_test), "prob")
(engine <- rand_forest(
mtry = 2,
trees = 500,
min_n = 10
) %>%
set_mode("classification") %>%
set_engine("ranger"))
fit <- engine %>%
fit(churn ~ ., data = juice(recipe_prep))
pred <- predict(fit, bake(recipe_prep, df_test), "prob")
str(fit, max.level = 1)
str(fit$spec, max.level = 1)
str(fit$fit, max.level = 1)
bake(recipe_with_shadow, df_train)
recipe <- df_train %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_prep <- prep(recipe)
bake(recipe_prep, df_train)
bake(recipe_prep, df_test)
recipe <- df_train %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_prep <- prep(recipe)
all_equal(
bake(recipe_prep, df_train),
bake(recipe_prep, df_test)
)
recipe <- df_train %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_prep <- prep(recipe)
all_equal(
bake(recipe_prep, df_train),
bake(recipe_prep, df_test),ignore_row_order = TRUE
)
?all_equal
recipe <- df_train %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_prep <- prep(recipe)
all_equal(
bake(recipe_prep, df_train),
bake(recipe_prep, df_test),
)
(fit <- rand_forest(
# mtry = 2,
# trees = 500,
# min_n = 10
) %>%
set_mode("classification") %>%
set_engine("ranger"))
fit <- engine %>%
fit(churn ~ ., data = juice(recipe_prep))
pred <- predict(fit, bake(recipe_prep, df_test), "prob")
(fit <- rand_forest() %>%
set_mode("classification") %>%
set_engine("ranger")) %>%
fit(churn ~ ., data = juice(recipe_prep))
pred <- predict(fit, bake(recipe_prep, df_test), "prob")
(fit <- rand_forest() %>%
set_mode("classification") %>%
set_engine("ranger")) %>%
fit(churn ~ ., data = juice(recipe_prep))
pred <- predict(fit, bake(recipe_prep, df_test), "prob")
(fit <- rand_forest() %>%
set_mode("classification") %>%
set_engine("ranger") %>%
fit(churn ~ ., data = juice(recipe_prep)))
pred <- predict(fit, bake(recipe_prep, df_test), "prob")
generate_missing <- function(df){
for(i in seq_along(df)){
if(runif(1, 0, 1) >= 0.50){
col <- df[[i]]
n_row <- length(col)
n_random <- n_row * runif(1, 0.01, 0.20)
indices <- round(runif(n_random, 0, n_row), 0)
df[[i]] <- replace(col, indices, NA)
} else {
next
}
}
return(df)
}
df_churn_na <- generate_missing(df_churn[, -1])
data("wa_churn")
df_churn <- wa_churn %>%
select(churn, female, senior_citizen, partner,
dependents, tenure, phone_service, contract,
multiple_lines, internet_service, streaming_tv,
streaming_movies, monthly_charges, total_charges)
glimpse(df_churn)
df_churn_na <- generate_missing(df_churn[, -1])
naniar::miss_var_summary(df_churn_na)
df_churn <- bind_cols(
df_churn[, 1],
df_churn_na
)
df_churn
split <- initial_split(df_churn, prop = 0.80, strata = "churn")
df_train <- training(split)
df_test  <- testing(split)
recipe <- df_train %>%
recipe(churn ~ .) %>%
step_shadow_missing(all_predictors()) %>%
step_medianimpute(all_numeric()) %>%
step_modeimpute(all_nominal(), -churn) %>%
step_dummy(all_nominal(), -churn) %>%
step_upsample(churn)
recipe_prep <- prep(recipe)
all_equal(
bake(recipe_prep, df_train),
bake(recipe_prep, df_test),
)
(fit <- rand_forest() %>%
set_mode("classification") %>%
set_engine("ranger") %>%
fit(churn ~ ., data = juice(recipe_prep)))
pred <- predict(fit, bake(recipe_prep, df_test), "prob")
train <-
data_frame(
a = c("a", "b", NA),
b = c(NA, "d", "e"),
c = c("f", "g", "h")
)
test <-
data_frame(
a = c(NA, NA, NA),
b = c(NA, "d", "e"),
c = c(NA, "f", "g")
)
rec <- recipe(train) %>%
step_shadow_missing(a, b, c) %>%
prep()
bake(rec, train)
bake(rec, test)
train <-
data_frame(
a = c("a", "b", NA),
b = c(NA, "d", "e"),
c = c("f", "g", "h")
)
test <-
data_frame(
a = c(NA, NA, NA),
b = c(NA, "d", "e"),
c = c(NA, "f", "g")
)
rec <- recipe(train) %>%
step_shadow_missing(a, b, c) %>%
prep()
bake(rec, train)
bake(rec, test)
data("wa_churn")
df_churn <- wa_churn %>%
select(churn, female, senior_citizen, partner,
dependents, tenure, phone_service, contract,
multiple_lines, internet_service, streaming_tv,
streaming_movies, monthly_charges, total_charges)
glimpse(df_churn)
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
library(blogdown)
blogdown::serve_site()
?blogdown::install_theme()
blogdown::install_theme(theme = "hugo-tranquilpeak-theme", update_config = TRUE)
blogdown::install_theme(theme = "kakawait/hugo-tranquilpeak-theme", update_config = TRUE)
install.packages("vip")
install.packages("vip")
set.seed(42)
options(max.print = 150)
library(tidymodels)
library(tidyverse)
library(caret)
library(magrittr)
library(naniar)
library(furrr)
library(skimr)
library(vip)
plan(multicore)
data("credit_data")
glimpse(credit_data)
credit_data %<>%
set_names(., tolower(names(.)))
split <- initial_split(credit_data, prop = 0.80, strata = "status")
df_train <- training(split)
df_test  <- testing(split)
train_cv <- vfold_cv(df_train, v = 5, strata = "status")
train_cv_caret <- rsample2caret(train_cv)
# write_rds(split, "split.rds")
# write_rds(train_cv, "train_cv.rds")
# Specifying the modelling engine
(engine_tidym <- rand_forest(mode = "classification") %>%
set_engine("ranger"))
# Specifying the grid of hyperparameters that should be tested
(gridy_tidym <- grid_random(
mtry %>% range_set(c( 1,  20)),
trees %>% range_set(c( 500, 1000)),
min_n %>% range_set(c(2,  10)),
size = 30
))
# Specifying the grid of hyperparameters that should be tested
(gridy_tidym <- grid_random(
mtry() %>% range_set(c(1,  20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2,  10)),
size = 30
))
install.packages("workflows")
install.packages("workflows")
library(workflows)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
recipe <- df_train %>%
recipe(status ~ .) %>%
# Imputation: assigning NAs to a new level for categorical and median imputation for numeric
step_unknown(all_nominal(), -status) %>%
step_medianimpute(all_numeric()) %>%
# Combining infrequent categorical levels and introducing a new level for prediction time
step_other(all_nominal(), -status, other = "infrequent_combined") %>%
step_novel(all_nominal(), -status, new_level = "unrecorded_observation") %>%
# Hot-encoding categorical variables
step_dummy(all_nominal(), -status, one_hot = TRUE) %>%
# Taking care of output consistency
check_missing(all_predictors())
(recipe_preped <- prep(recipe, retain = TRUE))
tidy(recipe_preped)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
wkfl_tidym
library(workflows)
library(tidymodels)
library(tune)
?tune_grid
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control(save_preds = TRUE)
)
# Specifying the modelling engine
(engine_tidym <- rand_forest(mode = "classification") %>%
set_engine("ranger"))
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control(save_preds = TRUE)
)
recipe <- df_train %>%
recipe(status ~ .) %>%
# Imputation: assigning NAs to a new level for categorical and median imputation for numeric
step_unknown(all_nominal(), -status) %>%
step_medianimpute(all_numeric()) %>%
# Combining infrequent categorical levels and introducing a new level for prediction time
step_other(all_nominal(), -status, other = "infrequent_combined") %>%
step_novel(all_nominal(), -status, new_level = "unrecorded_observation") %>%
# Hot-encoding categorical variables
step_dummy(all_nominal(), -status, one_hot = TRUE)
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control(save_preds = TRUE)
)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_preds = TRUE)
)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
gridy_tidym
?range_set
# Specifying the modelling engine
(engine_tidym <- rand_forest(
mode = "classification",
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine("ranger"))
# Specifying the grid of hyperparameters that should be tested
(gridy_tidym <- grid_regular(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
levels = 30
))
# Specifying the grid of hyperparameters that should be tested
(gridy_tidym <- grid_regular(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
levels = 3
))
# Specifying the grid of hyperparameters that should be tested
(gridy_tidym <- grid_random(
mtry() %>% range_set(c(1, 20)),
trees() %>% range_set(c(500, 1000)),
min_n() %>% range_set(c(2, 10)),
size = 30
))
wkfl_tidym <- workflow() %>%
add_recipe(recipe) %>%
add_model(engine_tidym)
grid_tidym <- tune_grid(
wkfl_tidym,
resamples = train_cv,
grid = gridy_tidym,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
grid_tidym
collect_metrics(grid_tidym)
collect_predictions(grid_tidym)
collect_metrics(grid_tidym)
(grid_tidym_best <- select_best(grid_tidym))
(finalize_workflow(wkfl_tidym, grid_tidym_best))
show_best(grid_tidym)
show_best(grid_tidym, n_top = 1)$mean
set.seed(42)
options(max.print = 150)
library(tidymodels)
library(tidyverse)
library(caret)
library(magrittr)
library(naniar)
library(furrr)
library(skimr)
library(vip)
library(workflows)
library(tune)
plan(multicore)
data("credit_data")
split <- initial_split(credit_data, prop = 0.80, strata = "status")
table(credit_data$status)
round(prop.table(table(credit_data$status)), 2)
glimpse(credit_data)
credit_data %<>%
set_names(., tolower(names(.)))
set.seed(42)
options(max.print = 150)
library(tidymodels)
library(tidyverse)
library(caret)
library(magrittr)
library(naniar)
library(furrr)
library(skimr)
library(vip)
library(workflows)
library(tune)
plan(multicore)
data("credit_data")
glimpse(credit_data)
credit_data %<>%
set_names(., tolower(names(.)))
tolower(names(credit_data))
credit_data %<>%
set_names(., tolower(names(.)))
credit_data
split <- initial_split(credit_data, prop = 0.80, strata = "status")
df_train <- training(split)
df_test  <- testing(split)
train_cv <- vfold_cv(df_train, v = 5, strata = "status")
train_cv_caret <- rsample2caret(train_cv)
# write_rds(split, "split.rds")
# write_rds(train_cv, "train_cv.rds")
test <- last_fit(wkfl_tidym, split = split)
install.packages("tune")
install.packages("tune")
library(tune)
